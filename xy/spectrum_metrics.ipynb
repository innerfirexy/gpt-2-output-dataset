{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from scipy import interpolate\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 从csv文件中读出每个区间，区分方法为每个区间必须升序\n",
    "def getInterval(fre_power_filepath:str):\n",
    "    spectrum = pd.read_csv(fre_power_filepath)\n",
    "    spectrum['group'] = (spectrum['freq'].shift(1) > spectrum['freq']).cumsum() # 聪明的办法！\n",
    "    grouped_spectrum = spectrum.groupby('group')\n",
    "    freq_list = []\n",
    "    power_list = []\n",
    "    for name, group in grouped_spectrum:\n",
    "        freq_list.append(group['freq'].tolist())\n",
    "        power_list.append(group['power'].tolist())\n",
    "    return freq_list, power_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test the shift() and groupby() methods\n",
    "entropy_file1 = '../data/large-762M.test.model=gpt2.nll'\n",
    "entropy_file2 = '../data/webtext.test.model=gpt2.nll'\n",
    "fp_file1 = '../plot/large-762M.test.model=gpt2.freq_power.csv'\n",
    "fp_file2 = '../plot/webtext.test.model=gpt2.freq_power.csv'\n",
    "\n",
    "spectrum = pd.read_csv(fp_file1)\n",
    "spectrum['group'] = (spectrum['freq'].shift(1) > spectrum['freq']).cumsum()\n",
    "spectrum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 返回由散点模拟的函数（可以为线性，二次方程或者三次方程）\n",
    "def getF(freq_list:list, power_list:list):\n",
    "    f = interpolate.interp1d(freq_list, power_list, fill_value=\"extrapolate\")\n",
    "    return f"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 根据两个文件内容， 返回每个区间固定且相同间隔的x对应的y值，区间取值为[0, 0.5],区间外的点是否需要计算？ or直接截断 比如0.48 去预测 0.5\n",
    "def alignPoints(filepath1:str, filepath2:str, n_common:int = 200, sort=False, verbose=False):\n",
    "    freq_list_list_1, power_list_list_1 = getInterval(filepath1)\n",
    "    freq_list_list_2, power_list_list_2 = getInterval(filepath2)\n",
    "    # sort the freq_list_list based on the length of the list\n",
    "    if sort:\n",
    "        freq_list_list_1.sort(key=len)\n",
    "        power_list_list_1.sort(key=len)\n",
    "        freq_list_list_2.sort(key=len)\n",
    "        power_list_list_2.sort(key=len)\n",
    "    if verbose:\n",
    "        print(f'There are {len(freq_list_list_1)},{len(freq_list_list_2)} intervals in file {filepath1},{filepath2} respectively')\n",
    "\n",
    "    x = np.linspace(0, 0.5, n_common)\n",
    "    y1listlist, y2listlist = [], []\n",
    "    for i in range(len(freq_list_list_1)):\n",
    "        freq_list1 = freq_list_list_1[i]\n",
    "        power_list1 = power_list_list_1[i]\n",
    "        freq_list2 = freq_list_list_2[i]\n",
    "        power_list2 = power_list_list_2[i]\n",
    "\n",
    "        func1 = getF(freq_list1, power_list1)\n",
    "        func2 = getF(freq_list2, power_list2)\n",
    "        # interpolate\n",
    "        y1 = func1(x)\n",
    "        y2 = func2(x)\n",
    "        y1listlist.append(y1)\n",
    "        y2listlist.append(y2)\n",
    "\n",
    "    return x, y1listlist, y2listlist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 为每个fre区间计算auc\n",
    "def getPSO(filepath1:str, filepath2:str):\n",
    "    area_floor_list, area_roof_list, pso_list = [], [], []\n",
    "    xlist, y1listlist, y2listlist = alignPoints(filepath1, filepath2)\n",
    "\n",
    "    for i in range(len(y1listlist)):\n",
    "        y1list = y1listlist[i]\n",
    "        y2list = y2listlist[i]\n",
    "        ylists = []\n",
    "        ylists.append(y1list)\n",
    "        ylists.append(y2list)\n",
    "\n",
    "        y_intersection = np.amin(ylists, axis=0)\n",
    "        y_roof = np.amax(ylists, axis=0)\n",
    "        area_floor = np.trapz(y_intersection, xlist)\n",
    "        area_roof = np.trapz(y_roof, xlist)\n",
    "\n",
    "        area_floor_list.append(area_floor)\n",
    "        area_roof_list.append(area_roof)\n",
    "        pso_list.append(round(area_floor / area_roof, 4))\n",
    "\n",
    "    return area_floor_list, area_roof_list, pso_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# 为每个fre区间计算PearsonCorelation\n",
    "def getPearson(filepath1:str, filepath2:str):\n",
    "    xlist, y1listlist, y2listlist = alignPoints(filepath1, filepath2)\n",
    "    corr_list = []\n",
    "    for i in range(len(y1listlist)):\n",
    "        y1list = y1listlist[i]\n",
    "        y2list = y2listlist[i]\n",
    "        y1 = np.array(y1list)\n",
    "        y2 = np.array(y2list)\n",
    "        finite_indices = np.logical_and(np.isfinite(y1), np.isfinite(y2))\n",
    "        y1 = y1[finite_indices]\n",
    "        y2 = y2[finite_indices]\n",
    "        try:\n",
    "            corr, _ = pearsonr(y1, y2)\n",
    "        except ValueError:\n",
    "            print(len(y1list), len(y2list))\n",
    "            print(y1.shape, y2.shape)\n",
    "            raise\n",
    "        corr_list.append(corr)\n",
    "    return corr_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Calculate the similarity between two spectra using Spectral Angle Mapper\n",
    "def getSAM(filepath1:str, filepath2:str):\n",
    "    xlist, y1listlist, y2listlist = alignPoints(filepath1, filepath2)\n",
    "    sam_list = []\n",
    "    for i in range(len(y1listlist)):\n",
    "        y1list = y1listlist[i]\n",
    "        y2list = y2listlist[i]\n",
    "        ylists = []\n",
    "        ylists.append(y1list)\n",
    "        ylists.append(y2list)\n",
    "        # Normalize the spectra\n",
    "        y1list /= np.linalg.norm(y1list)\n",
    "        y2list /= np.linalg.norm(y2list)\n",
    "        # Calculate the dot product\n",
    "        dot_product = np.dot(y1list, y2list)\n",
    "        # Calculate the SAM similarity\n",
    "        sam_similarity = np.arccos(dot_product) / np.pi\n",
    "        sam_list.append(sam_similarity)\n",
    "\n",
    "    return sam_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yang.xu/.pyenv/versions/3.9.14/lib/python3.9/site-packages/scipy/interpolate/_interpolate.py:653: RuntimeWarning: divide by zero encountered in divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n",
      "/Users/yang.xu/.pyenv/versions/3.9.14/lib/python3.9/site-packages/scipy/interpolate/_interpolate.py:656: RuntimeWarning: invalid value encountered in multiply\n",
      "  y_new = slope*(x_new - x_lo)[:, None] + y_lo\n",
      "/Users/yang.xu/.pyenv/versions/3.9.14/lib/python3.9/site-packages/scipy/interpolate/_interpolate.py:653: RuntimeWarning: divide by zero encountered in divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n",
      "/Users/yang.xu/.pyenv/versions/3.9.14/lib/python3.9/site-packages/scipy/interpolate/_interpolate.py:656: RuntimeWarning: invalid value encountered in multiply\n",
      "  y_new = slope*(x_new - x_lo)[:, None] + y_lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999 4999 4999\n"
     ]
    }
   ],
   "source": [
    "fp_file1 = '../plot/large-762M.test.model=gpt2.freq_power.csv'\n",
    "fp_file2 = '../plot/webtext.test.model=gpt2.freq_power.csv'\n",
    "x, y1listlist, y2listlist = alignPoints(fp_file1, fp_file2)\n",
    "\n",
    "area_floor_list, area_roof_list, pso_list = getPSO(fp_file1, fp_file2)\n",
    "print(len(area_floor_list), len(area_roof_list), len(pso_list))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yang.xu/.pyenv/versions/3.9.14/lib/python3.9/site-packages/scipy/interpolate/_interpolate.py:653: RuntimeWarning: divide by zero encountered in divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n",
      "/Users/yang.xu/.pyenv/versions/3.9.14/lib/python3.9/site-packages/scipy/interpolate/_interpolate.py:656: RuntimeWarning: invalid value encountered in multiply\n",
      "  y_new = slope*(x_new - x_lo)[:, None] + y_lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n"
     ]
    }
   ],
   "source": [
    "corr_list = getPearson(fp_file1, fp_file2)\n",
    "print(len(corr_list))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yang.xu/.pyenv/versions/3.9.14/lib/python3.9/site-packages/scipy/interpolate/_interpolate.py:653: RuntimeWarning: divide by zero encountered in divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n",
      "/Users/yang.xu/.pyenv/versions/3.9.14/lib/python3.9/site-packages/scipy/interpolate/_interpolate.py:656: RuntimeWarning: invalid value encountered in multiply\n",
      "  y_new = slope*(x_new - x_lo)[:, None] + y_lo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999\n"
     ]
    }
   ],
   "source": [
    "sam_list = getSAM(fp_file1, fp_file2)\n",
    "print(len(sam_list))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3869626450580232\n",
      "0.04771419768822357\n"
     ]
    }
   ],
   "source": [
    "pso_arr = np.array(pso_list)\n",
    "pso_arr = pso_arr[~np.isnan(pso_arr)]\n",
    "print(np.mean(pso_arr))\n",
    "print(np.std(pso_arr))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.040044331175459094\n",
      "0.10829241054950708\n"
     ]
    }
   ],
   "source": [
    "corr_arr = np.array(corr_list)\n",
    "corr_arr = corr_arr[~np.isnan(corr_arr)]\n",
    "print(np.mean(corr_arr))\n",
    "print(np.std(corr_arr))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30358397329042336\n",
      "0.028562383954158607\n"
     ]
    }
   ],
   "source": [
    "sam_arr = np.array(sam_list)\n",
    "sam_arr = sam_arr[~np.isnan(sam_arr)]\n",
    "print(np.mean(sam_arr))\n",
    "print(np.std(sam_arr))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Write pso_arr, corr_arr, sam_arr to .csv files\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pso_arr)\n",
    "df.to_csv('pso_arr.csv', index=False, header=False)\n",
    "\n",
    "df = pd.DataFrame(corr_arr)\n",
    "df.to_csv('corr_arr.csv', index=False, header=False)\n",
    "\n",
    "df = pd.DataFrame(sam_arr)\n",
    "df.to_csv('sam_arr.csv', index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "###\n",
    "# Experiments with OPT and SO metric\n",
    "###\n",
    "import os\n",
    "import glob\n",
    "import SpectrumTools as st\n",
    "\n",
    "fft_results_dir = \"../data/experiments_data/opt-original/\"\n",
    "gs_news_dir = \"../data/gs_james/gs_news/\"\n",
    "gs_story_dir = \"../data/gs_james/gs_story/\"\n",
    "gs_wiki_dir = \"../data/gs_james/gs_wiki/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "['webtext.train_opt_6.7b_top_50_wiki.sorted.split.0.fft.csv', 'webtext.train_opt_6.7b_top_50_wiki.sorted.split.200.fft.csv', 'webtext.train_opt_6.7b_top_50_wiki.sorted.split.400.fft.csv', 'webtext.train_opt_6.7b_top_50_wiki.sorted.split.600.fft.csv', 'webtext.train_opt_6.7b_top_50_wiki.sorted.split.800.fft.csv']\n"
     ]
    }
   ],
   "source": [
    "all_opt_files = glob.glob(os.path.join(fft_results_dir, '*.fft.csv'))\n",
    "print(len(all_opt_files))\n",
    "\n",
    "opt_sm_news = [f for f in all_opt_files if 'news' in f and '125m' in f]\n",
    "print(len(opt_sm_news))\n",
    "opt_sm_story = [f for f in all_opt_files if 'story' in f and '125m' in f]\n",
    "print(len(opt_sm_story))\n",
    "opt_sm_wiki = [f for f in all_opt_files if 'wiki' in f and '125m' in f]\n",
    "print(len(opt_sm_wiki))\n",
    "\n",
    "opt_bg_news = [f for f in all_opt_files if 'news' in f and '6.7b' in f]\n",
    "print(len(opt_bg_news))\n",
    "opt_bg_story = [f for f in all_opt_files if 'story' in f and '6.7b' in f]\n",
    "print(len(opt_bg_story))\n",
    "opt_bg_wiki = [f for f in all_opt_files if 'wiki' in f and '6.7b' in f]\n",
    "print(len(opt_bg_wiki))\n",
    "print(sorted([os.path.basename(f) for f in opt_bg_wiki]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "5\n",
      "['webtext.train.model=.wiki_0.fft.csv', 'webtext.train.model=.wiki_1.fft.csv', 'webtext.train.model=.wiki_2.fft.csv', 'webtext.train.model=.wiki_3.fft.csv', 'webtext.train.model=.wiki_4.fft.csv']\n"
     ]
    }
   ],
   "source": [
    "gs_news = glob.glob(os.path.join(gs_news_dir, '*.csv'))\n",
    "print(len(gs_news))\n",
    "\n",
    "gs_story = glob.glob(os.path.join(gs_story_dir, '*.csv'))\n",
    "print(len(gs_story))\n",
    "\n",
    "gs_wiki = glob.glob(os.path.join(gs_wiki_dir, '*.csv'))\n",
    "print(len(gs_wiki))\n",
    "print(sorted([os.path.basename(f) for f in gs_wiki]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/experiments_data/opt-original/webtext.train_opt_125m_top_50_news.sorted.split.0.fft.csv', '../data/experiments_data/opt-original/webtext.train_opt_125m_top_50_news.sorted.split.200.fft.csv', '../data/experiments_data/opt-original/webtext.train_opt_125m_top_50_news.sorted.split.400.fft.csv', '../data/experiments_data/opt-original/webtext.train_opt_125m_top_50_news.sorted.split.600.fft.csv', '../data/experiments_data/opt-original/webtext.train_opt_125m_top_50_news.sorted.split.800.fft.csv']\n",
      "['../data/gs_james/gs_news/webtext.train.model=.news_0.fft.csv', '../data/gs_james/gs_news/webtext.train.model=.news_1.fft.csv', '../data/gs_james/gs_news/webtext.train.model=.news_2.fft.csv', '../data/gs_james/gs_news/webtext.train.model=.news_3.fft.csv', '../data/gs_james/gs_news/webtext.train.model=.news_4.fft.csv']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(opt_sm_news))\n",
    "print(sorted(gs_news))\n",
    "\n",
    "opt_sm_news = sorted(opt_sm_news)\n",
    "opt_sm_story = sorted(opt_sm_story)\n",
    "opt_sm_wiki = sorted(opt_sm_wiki)\n",
    "\n",
    "opt_bg_news = sorted(opt_bg_news)\n",
    "opt_bg_story = sorted(opt_bg_story)\n",
    "opt_bg_wiki = sorted(opt_bg_wiki)\n",
    "\n",
    "gs_news = sorted(gs_news)\n",
    "gs_story = sorted(gs_story)\n",
    "gs_wiki = sorted(gs_wiki)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "844\n",
      "1220\n",
      "1194\n",
      "764\n",
      "978\n"
     ]
    }
   ],
   "source": [
    "# length_split_strs1 = ['0', '200', '400', '600', '800']\n",
    "# length_split_strs2 = ['0', '1', '2', '3', '4']\n",
    "\n",
    "# sm news\n",
    "so_sm_news_list = []\n",
    "for i in range(len(opt_sm_news)):\n",
    "    opt_file = opt_sm_news[i]\n",
    "    gs_file = gs_news[i]\n",
    "    _, _, so_sm_news = st.getPSO(opt_file, gs_file)\n",
    "    so_sm_news_list.append(so_sm_news)\n",
    "\n",
    "print(len(so_sm_news_list))\n",
    "for li in so_sm_news_list:\n",
    "    print(len(li))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# sm story\n",
    "so_sm_story_list = []\n",
    "for i in range(len(opt_sm_story)):\n",
    "    opt_file = opt_sm_story[i]\n",
    "    gs_file = gs_story[i]\n",
    "    _, _, so_sm_story = st.getPSO(opt_file, gs_file)\n",
    "    so_sm_story_list.append(so_sm_story)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# sm wiki\n",
    "so_sm_wiki_list = []\n",
    "for i in range(len(opt_sm_wiki)):\n",
    "    opt_file = opt_sm_wiki[i]\n",
    "    gs_file = gs_wiki[i]\n",
    "    _, _, so_sm_wiki = st.getPSO(opt_file, gs_file)\n",
    "    so_sm_wiki_list.append(so_sm_wiki)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# bg news\n",
    "so_bg_news_list = []\n",
    "for i in range(len(opt_bg_news)):\n",
    "    opt_file = opt_bg_news[i]\n",
    "    gs_file = gs_news[i]\n",
    "    _, _, so_bg_news = st.getPSO(opt_file, gs_file)\n",
    "    so_bg_news_list.append(so_bg_news)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# bg story\n",
    "so_bg_story_list = []\n",
    "for i in range(len(opt_bg_story)):\n",
    "    opt_file = opt_bg_story[i]\n",
    "    gs_file = gs_story[i]\n",
    "    _, _, so_bg_story = st.getPSO(opt_file, gs_file)\n",
    "    so_bg_story_list.append(so_bg_story)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# bg wiki\n",
    "so_bg_wiki_list = []\n",
    "for i in range(len(opt_bg_wiki)):\n",
    "    opt_file = opt_bg_wiki[i]\n",
    "    gs_file = gs_wiki[i]\n",
    "    _, _, so_bg_wiki = st.getPSO(opt_file, gs_file)\n",
    "    so_bg_wiki_list.append(so_bg_wiki)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000 5000\n",
      "5000 5000 5000\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "so_sm_news = list(chain.from_iterable(so_sm_news_list))\n",
    "so_sm_story = list(chain.from_iterable(so_sm_story_list))\n",
    "so_sm_wiki = list(chain.from_iterable(so_sm_wiki_list))\n",
    "print(len(so_sm_news), len(so_sm_story), len(so_sm_wiki))\n",
    "\n",
    "so_bg_news = list(chain.from_iterable(so_bg_news_list))\n",
    "so_bg_story = list(chain.from_iterable(so_bg_story_list))\n",
    "so_bg_wiki = list(chain.from_iterable(so_bg_wiki_list))\n",
    "print(len(so_bg_news), len(so_bg_story), len(so_bg_wiki))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Save all SO results\n",
    "import pandas as pd\n",
    "\n",
    "df_so = pd.DataFrame({'so_sm_news': so_sm_news,\n",
    "                      'so_sm_story': so_sm_story,\n",
    "                      'so_sm_wiki': so_sm_wiki,\n",
    "                      'so_bg_news': so_bg_news,\n",
    "                      'so_bg_story': so_bg_story,\n",
    "                      'so_bg_wiki': so_bg_wiki})\n",
    "df_so.to_csv('OPT_SO.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 15000\n"
     ]
    }
   ],
   "source": [
    "so_sm = so_sm_news + so_sm_story + so_sm_wiki\n",
    "so_bg = so_bg_news + so_bg_story + so_bg_wiki\n",
    "print(len(so_sm), len(so_bg))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.839365344620955 1.0143137933061228e-18\n",
      "0.4227081466666667 0.42691802\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# t-test\n",
    "from scipy import stats\n",
    "\n",
    "t, p = stats.ttest_ind(so_sm, so_bg, equal_var=False)\n",
    "print(t, p)\n",
    "\n",
    "print(np.mean(so_sm), np.mean(so_bg))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43809636 0.40555068 0.42447739999999995\n",
      "0.44000948000000006 0.40467664 0.43606794\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(so_sm_news), np.mean(so_sm_story), np.mean(so_sm_wiki))\n",
    "print(np.mean(so_bg_news), np.mean(so_bg_story), np.mean(so_bg_wiki))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.7800744793525 0.00015769357583737378\n"
     ]
    }
   ],
   "source": [
    "t, p = stats.ttest_ind(so_sm_news, so_bg_news, equal_var=False)\n",
    "print(t, p)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8358859957808088 0.4032391919713635\n"
     ]
    }
   ],
   "source": [
    "t, p = stats.ttest_ind(so_sm_story, so_bg_story, equal_var=False)\n",
    "print(t, p)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-17.566796628191792 4.6588623166578475e-68\n"
     ]
    }
   ],
   "source": [
    "t, p = stats.ttest_ind(so_sm_wiki, so_bg_wiki, equal_var=False)\n",
    "print(t, p)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
